{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1766c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82cf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "amazon_root_path = os.path.join(root_path,\"amazonOutput\")\n",
    "\n",
    "images_root_path = os.path.join(root_path,\"imagesPerPage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5bbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = \"./credentials.json\"\n",
    "\n",
    "with open(credentials,\"rb\") as file:\n",
    "    creds = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5e758",
   "metadata": {},
   "source": [
    "<h2>Call Amazon Textract Service</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5798a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_extract_client(aws_creds):\n",
    "    \"\"\"\n",
    "    Used to return credentials for amazon textract client.\n",
    "    Requests for Token for mfa validation\n",
    "    \n",
    "    \"\"\"\n",
    "    mfa_linked_access_id = aws_creds[\"access_id\"]\n",
    "    mfa_linked_secret_key = aws_creds[\"secret_key\"]\n",
    "    region = aws_creds[\"region\"]\n",
    "    mfa_serial = aws_creds[\"mfa\"]\n",
    "    role_arn = aws_creds[\"role_arn\"]\n",
    "    \n",
    "    role_session_name = 'testRole'\n",
    "    \n",
    "    sts_client = boto3.client('sts',\n",
    "          region_name=region,\n",
    "          aws_access_key_id=mfa_linked_access_id,\n",
    "          aws_secret_access_key=mfa_linked_secret_key)\n",
    "    \n",
    "    mfa_token = input(\"Enter Token: \")\n",
    "    \n",
    "    mfa_response = sts_client.get_session_token(\n",
    "        DurationSeconds=129600, \n",
    "        SerialNumber=mfa_serial,\n",
    "        TokenCode=mfa_token\n",
    "    )\n",
    "    \n",
    "    credentials = mfa_response['Credentials']\n",
    "        \n",
    "    new_sts_client = boto3.client('sts',                          \n",
    "                          aws_access_key_id=credentials[\"AccessKeyId\"],\n",
    "                          aws_secret_access_key=credentials[\"SecretAccessKey\"],\n",
    "                          aws_session_token=credentials[\"SessionToken\"])\n",
    "    \n",
    "    # Change role\n",
    "    assumed_role = new_sts_client.assume_role(\n",
    "        RoleArn=role_arn,\n",
    "        RoleSessionName=role_session_name)\n",
    "    \n",
    "    \n",
    "    role_credentials = assumed_role['Credentials']\n",
    "    role_credentials[\"region\"] = creds[\"region\"]\n",
    "    \n",
    "    text_client = boto3.client('textract',                          \n",
    "              aws_access_key_id=role_credentials[\"AccessKeyId\"],\n",
    "              aws_secret_access_key=role_credentials[\"SecretAccessKey\"],\n",
    "              aws_session_token=role_credentials[\"SessionToken\"],\n",
    "              region_name=role_credentials[\"region\"])\n",
    "    \n",
    "    return text_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64632fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Token: 250286\n"
     ]
    }
   ],
   "source": [
    "# Create Textract Client\n",
    "client = create_text_extract_client(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d70618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder --> oncoextra-tnbc-ntrk-wm-sample-report_pdf\n",
      "Processing Folder --> Caris-Molecular-Intelligence_MI-Profile_Breast_NOS_WEBchanged_pdf\n",
      "Processing Folder --> F1CDx Sample Report (Lung) (copy)_pdf\n",
      "Processing Folder --> F1CDx Sample Report (Lung) changed_pdf\n",
      "Processing Folder --> CarisReport_2023_NSCLC_KRAS_G12C_PD-L1-unlocked_pdf\n",
      "Processing Folder --> Sample-NGS-Thyroid-MTC-report_changed_pdf\n",
      "Processing Folder --> Tempus-Onco_Clinical-Report-Sample_pdf\n",
      "Processing Folder --> Positive-Report_pdf\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(images_root_path):\n",
    "    print(f\"Processing Folder --> {folder}\", end=\"\\n\")\n",
    "    \n",
    "    folder_dir = os.path.join(images_root_path,folder)\n",
    "    amazon_dir = os.path.join(amazon_root_path,folder,\"annotation\")\n",
    "    \n",
    "    os.makedirs(amazon_dir,exist_ok=True)\n",
    "    \n",
    "    for image_file in os.listdir(folder_dir):\n",
    "        image_file_dir = os.path.join(folder_dir,image_file)\n",
    "        result_save_dir = os.path.join(amazon_dir,image_file.replace(\".png\",\".json\"))\n",
    "        \n",
    "        with open(image_file_dir,\"rb\") as load_file:\n",
    "            doc_bytes = load_file.read()\n",
    "        \n",
    "        response = client.analyze_document(Document={'Bytes': doc_bytes},FeatureTypes=['FORMS','TABLES'])\n",
    "        \n",
    "        with open(result_save_dir,\"w\") as write_file:\n",
    "            write_file.write(json.dumps(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae854e4",
   "metadata": {},
   "source": [
    "<h2>Extract Key-Value From Textract Response</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3bb0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kv_map(response):\n",
    "    # Get the text blocks\n",
    "    blocks = response['Blocks']\n",
    "\n",
    "    # get key and value maps\n",
    "    key_map = {}\n",
    "    value_map = {}\n",
    "    block_map = {}\n",
    "    for block in blocks:\n",
    "        block_id = block['Id']\n",
    "        block_map[block_id] = block\n",
    "        if block['BlockType'] == \"KEY_VALUE_SET\":\n",
    "            if 'KEY' in block['EntityTypes']:\n",
    "                key_map[block_id] = block\n",
    "            else:\n",
    "                value_map[block_id] = block\n",
    "\n",
    "    return key_map, value_map, block_map\n",
    "\n",
    "\n",
    "def get_kv_relationship(key_map, value_map, block_map):\n",
    "    kvs = defaultdict(list)\n",
    "    for block_id, key_block in key_map.items():\n",
    "        value_block = find_value_block(key_block, value_map)\n",
    "        key = get_text(key_block, block_map)\n",
    "        val = get_text(value_block, block_map)\n",
    "        kvs[key].append(val)\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def find_value_block(key_block, value_map):\n",
    "    for relationship in key_block['Relationships']:\n",
    "        if relationship['Type'] == 'VALUE':\n",
    "            for value_id in relationship['Ids']:\n",
    "                value_block = value_map[value_id]\n",
    "    return value_block\n",
    "\n",
    "                            \n",
    "def get_text(result, blocks_map,key=True):\n",
    "    text = ''\n",
    "    if 'Relationships' in result:\n",
    "        for relationship in result['Relationships']:\n",
    "            if relationship['Type'] == 'CHILD':\n",
    "                for child_id in relationship['Ids']:\n",
    "                    word = blocks_map[child_id]\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                        text += word['Text'] + \" \"\n",
    "                    if word['BlockType'] == 'SELECTION_ELEMENT':\n",
    "                        if word['SelectionStatus'] == 'SELECTED':\n",
    "                            text += 'X '\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f21c2",
   "metadata": {},
   "source": [
    "<h2>Extract Table From Textract Response</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14eeb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_columns_map(table_result, blocks_map):\n",
    "    rows = {}\n",
    "    scores = []\n",
    "    for relationship in table_result['Relationships']:\n",
    "        if relationship['Type'] == 'CHILD':\n",
    "            for child_id in relationship['Ids']:\n",
    "                cell = blocks_map[child_id]\n",
    "                if cell['BlockType'] == 'CELL':\n",
    "                    row_index = cell['RowIndex']\n",
    "                    col_index = cell['ColumnIndex']\n",
    "                    if row_index not in rows:\n",
    "                        # create new row\n",
    "                        rows[row_index] = {}\n",
    "                    \n",
    "                    # get confidence score\n",
    "                    scores.append(str(cell['Confidence']))\n",
    "                        \n",
    "                    # get the text value\n",
    "                    rows[row_index][col_index] = get_text(cell, blocks_map)\n",
    "    return rows, scores\n",
    "\n",
    "\n",
    "def get_text(result, blocks_map):\n",
    "    text = ''\n",
    "    if 'Relationships' in result:\n",
    "        for relationship in result['Relationships']:\n",
    "            if relationship['Type'] == 'CHILD':\n",
    "                for child_id in relationship['Ids']:\n",
    "                    word = blocks_map[child_id]\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                            text += word['Text'] + ' '\n",
    "                    if word['BlockType'] == 'SELECTION_ELEMENT':\n",
    "                        if word['SelectionStatus'] =='SELECTED':\n",
    "                            text +=  'X '\n",
    "    return text\n",
    "\n",
    "def generate_table_csv(table_result, blocks_map, table_index):\n",
    "    rows, scores = get_rows_columns_map(table_result, blocks_map)\n",
    "    \n",
    "    csv = ''\n",
    "    for row_index, cols in rows.items():\n",
    "        for col_index, text in cols.items():\n",
    "            col_indices = len(cols.items())\n",
    "            csv += '{}'.format(text) + \"<sep>\"\n",
    "        csv += '\\n'\n",
    "\n",
    "    csv += '\\n\\n'\n",
    "    return csv\n",
    "\n",
    "def get_table_csv_results(response):\n",
    "    \n",
    "    blocks=response['Blocks']\n",
    "    \n",
    "    blocks_map = {}\n",
    "    table_blocks = []\n",
    "    for block in blocks:\n",
    "        blocks_map[block['Id']] = block\n",
    "        if block['BlockType'] == \"TABLE\":\n",
    "            table_blocks.append(block)\n",
    "\n",
    "    if len(table_blocks) <= 0:\n",
    "        return \"<b> NO Table FOUND </b>\"\n",
    "\n",
    "    csv = ''\n",
    "    for index, table in enumerate(table_blocks):\n",
    "        csv += generate_table_csv(table, blocks_map, index +1)\n",
    "        csv += '\\n---End--OF--Table\\n'\n",
    "\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ef18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_from_csv(csv, file):\n",
    "    if \"<b> NO Table FOUND </b>\" in csv:\n",
    "        return {\"Comment\": \"No Table FOUND\"}\n",
    "    \n",
    "    tables = csv.split(\"\\n\\n\\n\\n---End--OF--Table\\n\")\n",
    "    \n",
    "    out = {}\n",
    "    \n",
    "    for table in tables:\n",
    "        table_lines = table.strip().split(\"\\n\")\n",
    "        table_lines = [line.split(\"<sep>\") for line in table_lines]\n",
    "        table_lines = [[ele for ele in line if ele.strip() != \"\"] for line in table_lines]\n",
    "        \n",
    "        # ignore empty tables\n",
    "        if not table_lines:\n",
    "            continue\n",
    "        \n",
    "        headers = table_lines[0]\n",
    "        header_count = len(headers)\n",
    "        \n",
    "        for row in table_lines[1:]:\n",
    "            \n",
    "            if len(row) >= header_count:\n",
    "                for header, value in zip(headers, row):\n",
    "                    if header.strip() not in out:\n",
    "                        out[header.strip()] = []\n",
    "                    out[header.strip()].append(value.strip())\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e1cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_table_kvs(table_json,kvs):\n",
    "    \"\"\"\n",
    "    Used to Combine Key-Value and Table Information\n",
    "    Into a single json per image file.\n",
    "    \"\"\"\n",
    "    \n",
    "    for key,value in kvs.items():\n",
    "        stripped_key = key.strip()\n",
    "        stripped_value = [i.strip() for i in value]\n",
    "\n",
    "        if stripped_key in table_json.keys():\n",
    "            table_json[stripped_key].extend(stripped_value)\n",
    "\n",
    "        else:\n",
    "            table_json[stripped_key] = []\n",
    "            table_json[stripped_key].extend(stripped_value)\n",
    "    \n",
    "    return table_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "849e8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(amazon_root_path):\n",
    "    if folder != \".DS_Store\":\n",
    "        annotation_dir = os.path.join(amazon_root_path,folder,\"annotation\")\n",
    "        results_dir = os.path.join(amazon_root_path,folder,\"results\")\n",
    "        \n",
    "        os.makedirs(results_dir,exist_ok=True)\n",
    "        \n",
    "        for jsonFile in os.listdir(annotation_dir):\n",
    "            payload_dir = os.path.join(annotation_dir,jsonFile)\n",
    "            table_save_dir = os.path.join(results_dir,jsonFile.split(\".json\")[0] + \"_table_result.csv\")\n",
    "            json_table_save_dir = os.path.join(results_dir,jsonFile.split(\".json\")[0] + \"_json_result.json\")\n",
    "\n",
    "            with open(payload_dir,\"r\") as load_file:\n",
    "                json_payload = json.loads(load_file.read())\n",
    "\n",
    "            csv = get_table_csv_results(json_payload)\n",
    "            table_json = generate_json_from_csv(csv,jsonFile)\n",
    "\n",
    "            key_map, value_map, block_map = get_kv_map(json_payload)\n",
    "            kvs = get_kv_relationship(key_map, value_map, block_map)\n",
    "\n",
    "            master = combine_table_kvs(table_json,kvs)\n",
    "                  \n",
    "            with open(table_save_dir,\"w\") as save_file:\n",
    "                save_file.write(csv)\n",
    "\n",
    "            with open(json_table_save_dir, \"w\") as json_save_file:\n",
    "                json_save_file.write(json.dumps(master))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
