{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766f4ce1",
   "metadata": {},
   "source": [
    "# Visual Document NER v2 FineTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a36dd",
   "metadata": {},
   "source": [
    "## Install spark-ocr python packge\n",
    "\n",
    "Need specify path to spark-ocr-assembly-[version].jar or secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41879608",
   "metadata": {},
   "source": [
    "### To simulate the build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d152db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b GH337_LayoutLMv2NER_Finetune --recurse-submodules https://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@github.com/JohnSnowLabs/spark-ocr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = \"\"\n",
    "license = \"\"\n",
    "version = secret.split(\"-\")[0]\n",
    "AWS_ACCESS_KEY_ID = \"\"\n",
    "AWS_SECRET_ACCESS_KEY = \"\"\n",
    "spark_ocr_jar_path = \"../../target/scala-2.11\"\n",
    "\n",
    "import os\n",
    "os.environ['JSL_OCR_LICENSE'] = license\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44751c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark==3.0.2\n",
    "!pip install git+https://github.com/fadi212/transformers.git@layoutlmv2_onnx\n",
    "!pip3 install torch==1.10.0 torchvision==0.11.1 torchaudio==0.10.0\n",
    "!pip install onnxruntime==1.10.0\n",
    "!pip install datasets==1.18.2 Pillow==7.1.2 pathlib==1.0.1\n",
    "!pip install pandas==1.3.5 tqdm==4.62.3 pytest-shutil==1.7.0\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install git+https://github.com/huggingface/datasets.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca56a81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7475df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spark-ocr==$version+spark30 --extra-index-url=https://pypi.johnsnowlabs.com/$secret --upgrade\n",
    "# !pip install ../../python/dist/spark-ocr-3.9.0+spark30.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685056c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"spark-ocr/python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sparkocr\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.utils import display_images\n",
    "from sparkocr.enums import *\n",
    "\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349e3fc",
   "metadata": {},
   "source": [
    "### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkocr import start\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = start(jar_path = spark_ocr_jar_path)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc49d7",
   "metadata": {},
   "source": [
    "## Load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "test_image_path = pkg_resources.resource_filename('sparkocr', 'resources/ocr/forms')\n",
    "bin_df = spark.read.format(\"binaryFile\").load(test_image_path)\n",
    "bin_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9c0a3",
   "metadata": {},
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = BinaryToImage().transform(bin_df)\n",
    "display_images(image_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22f513",
   "metadata": {},
   "source": [
    "## Prepare Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_to_image = BinaryToImage()\\\n",
    "    .setOutputCol(\"image\") \\\n",
    "    .setImageType(ImageType.TYPE_3BYTE_BGR)\n",
    "\n",
    "img_to_hocr = ImageToHocr()\\\n",
    "    .setInputCol(\"image\")\\\n",
    "    .setOutputCol(\"hocr\")\\\n",
    "    .setIgnoreResolution(False)\\\n",
    "    .setOcrParams([\"preserve_interword_spaces=0\"])\n",
    "\n",
    "tokenizer = HocrTokenizer()\\\n",
    "    .setInputCol(\"hocr\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "doc_ner = VisualDocumentNerV2()\\\n",
    "    .pretrained(\"layoutlmv2_funsd\", \"en\", \"clinical/ocr\")\\\n",
    "    .setInputCols([\"token\", \"image\"])\\\n",
    "    .setOutputCol(\"entities\")\\\n",
    "    .setWhiteList([\"other\", \"b-header\", \"i-header\", \"b-question\", \"i-question\", \"b-answer\", \"i-answer\"])\n",
    "\n",
    "draw = ImageDrawAnnotations() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setInputChunksCol(\"entities\") \\\n",
    "    .setOutputCol(\"image_with_annotations\") \\\n",
    "    .setFontSize(10) \\\n",
    "    .setLineWidth(4)\\\n",
    "    .setRectColor(Color.red)\n",
    "\n",
    "# OCR pipeline\n",
    "pipeline = PipelineModel(stages=[\n",
    "    binary_to_image,\n",
    "    img_to_hocr,\n",
    "    tokenizer,\n",
    "    doc_ner,\n",
    "    draw\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d06cc",
   "metadata": {},
   "source": [
    "## Prepare Pyspark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24935646",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipeline.transform(bin_df).cache()\n",
    "## since pyspark2.3 doesn't have element_at, 'getItem' is involked\n",
    "path_array = f.split(results['path'], '/')\n",
    "\n",
    "# from pyspark2.4\n",
    "# results.withColumn(\"filename\", f.element_at(f.split(\"path\", \"/\"), -1)) \\\n",
    "\n",
    "results.withColumn('filename', path_array.getItem(f.size(path_array)- 1)) \\\n",
    "    .withColumn(\"exploded_entities\", f.explode(\"entities\")) \\\n",
    "    .select(\"filename\", \"exploded_entities\") \\\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c85e50",
   "metadata": {},
   "source": [
    "### Define VisualDocumentNerV2 instance object for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a553e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ner = VisualDocumentNerV2()\\\n",
    "    .pretrained(\"layoutlmv2_funsd\", \"en\", \"clinical/ocr\")\\\n",
    "    .setInputCols([\"token\", \"image\"])\\\n",
    "    .setOutputCol(\"entities\")\\\n",
    "    .setWhiteList([\"other\", \"b-header\", \"i-header\", \"b-question\", \"i-question\", \"b-answer\", \"i-answer\"])\\\n",
    "    .setbatchSize(4)\\\n",
    "    .setShuffleBatchTraining(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc17b344",
   "metadata": {},
   "source": [
    "### Calling fit method for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nerv2 = doc_ner.fit(results, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9908e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = ''\n",
    "model_save_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05623016",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = open(vocab_path, \"r\")\n",
    "vocab = []\n",
    "for line in vocab_file:\n",
    "    vocab.append(line.strip())\n",
    "vocab_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nerv2.setVocabulary(vocab)\n",
    "model_nerv2.saveModel(model_path=model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
