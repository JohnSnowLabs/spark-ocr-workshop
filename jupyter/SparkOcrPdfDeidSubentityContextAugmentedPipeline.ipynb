{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea531aed",
   "metadata": {},
   "source": [
    "## PDF De-identification Pipeline\n",
    "This Pretrained Pipeline will de-identify PDFs documents, and write results back to PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0cc8ab-e073-4a26-9b50-d35012309b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "Spark NLP version: 5.4.0\n",
      "Spark NLP for Healthcare version: 5.3.2\n",
      "Spark OCR version: 5.4.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.16:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark OCR</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fafbbed0400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sparkocr\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "\n",
    "params = {\"spark.driver.memory\":\"20G\",\n",
    "          \"spark.executor.memory\":\"20G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "          \"spark.driver.maxResultSize\":\"2000M\",\n",
    "          \"spark.sql.legacy.allowUntypedScalaUDF\":True}\n",
    "\n",
    "\n",
    "spark = sparkocr.start(jar_path=\"../../target/scala-2.12\", nlp_secret=\"5.3.2-a959b3ea6db4a3891ac4fe241706834cb07d87c1\", nlp_internal=\"5.3.2\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f32db",
   "metadata": {},
   "source": [
    "\n",
    "## Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5876093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='./mr_simpson.pdf'\n",
    "pdfs = spark.read.format(\"binaryFile\").load(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91665ec6",
   "metadata": {},
   "source": [
    "## Run from PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0295e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_deid_subentity_context_augmented_pipeline download started this may take some time.\n",
      "Approx size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.pretrained import *\n",
    "pipeline = PretrainedPipeline(\"pdf_deid_subentity_context_augmented_pipeline\", \"en\", \"clinical/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3929f-ee96-4591-b73f-de2b1dff963a",
   "metadata": {},
   "source": [
    "## Write PDF to local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e4bfa9-0e57-4d60-99ea-adf22e9a8c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file to ./mr_simpson_deIdentified.pdf\n",
      "CPU times: user 88 ms, sys: 10.7 ms, total: 98.8 ms\n",
      "Wall time: 3.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = pipeline.transform(pdfs)\n",
    "outputPath = \"./\"\n",
    "for row in result.select(\"pdf\", \"path\").toLocalIterator():\n",
    "    inputFile = row.path\n",
    "    fileName = inputFile.split(\"/\")[-1].split(\".\")[0] + \"_deIdentified.pdf\"\n",
    "    outputFilePath = outputPath + fileName\n",
    "\n",
    "    print(f\"Saving file to {outputFilePath}\")\n",
    "    with open(outputFilePath, \"wb\") as f:\n",
    "        f.write(row.pdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b9b5ce-46df-433d-a95a-a45a4ad8aba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./tmp/pdf.pdf width=600 height=500></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{./tmp/pdf.pdf}"
      ],
      "text/plain": [
       "<sparkocr.utils.display_pdf_file at 0x7faf5ce7b9a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparkocr.utils import display_pdf_file\n",
    "display_pdf_file(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305a8b5-54a1-4207-a249-3eb2d33d74ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
