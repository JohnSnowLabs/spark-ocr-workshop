{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8fd9bcba-d574-4cd5-acbf-4242185cfa16",
      "metadata": {
        "id": "8fd9bcba-d574-4cd5-acbf-4242185cfa16",
        "outputId": "b0ff8340-6769-48bb-a61b-40c5530e2a97"
      },
      "source": [
        "# Visual NLP ChartToTextTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "306ce550",
        "outputId": "b72b51cf-cb40-4d35-f315-88bb00d4341d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe5342f6-e98b-4108-a54a-0a20517f22f6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fe5342f6-e98b-4108-a54a-0a20517f22f6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spark_nlp_for_healthcare_spark_ocr_8803 (1).json to spark_nlp_for_healthcare_spark_ocr_8803 (1).json\n"
          ]
        }
      ],
      "source": [
        "import json, os\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import files\n",
        "\n",
        "    if 'spark_ocr.json' not in os.listdir():\n",
        "      license_keys = files.upload()\n",
        "      os.rename(list(license_keys.keys())[0], 'spark_ocr.json')\n",
        "\n",
        "with open('spark_ocr.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)"
      ],
      "id": "306ce550"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eba2fcdb",
        "outputId": "d32f4fde-bebe-4bb8-ae0f-47fb26da98a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.3/547.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/5.2.0-8fe2fa510a6f424b2232f2066e44b31fb48753d9\n",
            "Collecting spark-ocr==5.2.0\n",
            "  Downloading https://pypi.johnsnowlabs.com/5.2.0-8fe2fa510a6f424b2232f2066e44b31fb48753d9/spark-ocr/spark_ocr-5.2.0-py3-none-any.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.15.0,>=0.7.0 (from spark-ocr==5.2.0)\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<=1.24.3,>=1.21.6 (from spark-ocr==5.2.0)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<=10.0.0,>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.2.0) (9.4.0)\n",
            "Requirement already satisfied: py4j>=0.10.9 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.2.0) (0.10.9.3)\n",
            "Requirement already satisfied: pyspark<=3.5.2,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.2.0) (3.2.1)\n",
            "Requirement already satisfied: scikit-image<=0.22.0,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.2.0) (0.19.3)\n",
            "Collecting implicits==1.0.2 (from spark-ocr==5.2.0)\n",
            "  Downloading implicits-1.0.2-py3-none-any.whl (3.7 kB)\n",
            "Collecting craft-text-detector==0.4.2 (from spark-ocr==5.2.0)\n",
            "  Downloading craft_text_detector-0.4.2-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: spark-nlp==5.2.2 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.2.0) (5.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector==0.4.2->spark-ocr==5.2.0) (2.2.1+cu121)\n",
            "Collecting opencv-python<4.5.4.62,>=3.4.8.29 (from craft-text-detector==0.4.2->spark-ocr==5.2.0)\n",
            "  Downloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector==0.4.2->spark-ocr==5.2.0) (1.11.4)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector==0.4.2->spark-ocr==5.2.0) (4.7.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.2.0) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.2.0) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.2.0) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.2.0) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.2.0) (24.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (2.31.0)\n",
            "Collecting torch>=1.6.0 (from craft-text-detector==0.4.2->spark-ocr==5.2.0)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m983.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.2.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.2.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.2.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.2.0) (0.43.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.2.0) (3.13.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.2.0) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.2.0) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.2.0) (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.2.0) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.2.0) (1.7.1)\n",
            "Installing collected packages: implicits, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, opencv-python, nvidia-cudnn-cu11, torch, torchvision, craft-text-detector, spark-ocr\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed craft-text-detector-0.4.2 implicits-1.0.2 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 opencv-python-4.5.4.60 spark-ocr-5.2.0 torch-1.13.1 torchvision-0.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2efe8321c34c4edd987f7c0c0b005f3d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "%pip install --upgrade -q pyspark==3.2.1 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark OCR\n",
        "#! pip uninstall spark-ocr -Y\n",
        "%pip install spark-ocr==$OCR_VERSION --extra-index-url=https://pypi.johnsnowlabs.com/$SPARK_OCR_SECRET --upgrade"
      ],
      "id": "eba2fcdb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45b70887"
      },
      "source": [
        "<b><h1><font color='darkred'>!!! ATTENTION !!! </font><h1><b>\n",
        "\n",
        "<b>After running previous cell, <font color='darkred'>RESTART the COLAB RUNTIME </font> and go ahead.<b>"
      ],
      "id": "45b70887"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9fd59396"
      },
      "outputs": [],
      "source": [
        "import json, os\n",
        "\n",
        "with open(\"spark_ocr.json\", 'r') as f:\n",
        "  license_keys = json.load(f)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)"
      ],
      "id": "9fd59396"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pnkUkvoHdiH5"
      },
      "outputs": [],
      "source": [
        "import pkg_resources\n",
        "\n",
        "from pyspark.ml import PipelineModel\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "from sparkocr import start\n",
        "from sparkocr.transformers import *\n",
        "from sparkocr.enums import *\n",
        "from sparkocr.utils import *\n",
        "from sparkocr.metrics import score\n",
        "\n",
        "from sparkocr.transformers import ChartToTextTable"
      ],
      "id": "pnkUkvoHdiH5"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0bcc4f-6212-43e1-f847-ee97b124cd24",
        "id": "FC_opbJVdvs_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.2.1\n",
            "Spark NLP version: 5.2.2\n",
            "Spark OCR version: 5.2.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Start spark\n",
        "spark = start(secret=SPARK_OCR_SECRET, nlp_version=PUBLIC_VERSION)"
      ],
      "id": "FC_opbJVdvs_"
    },
    {
      "cell_type": "markdown",
      "id": "e232fe08",
      "metadata": {
        "id": "e232fe08"
      },
      "source": [
        "### Define pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e49c355f",
      "metadata": {
        "id": "e49c355f",
        "outputId": "ed022cd4-31d6-4637-9de7-55af9b34f094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chart_to_text_deplot_jsl download started this may take some time.\n",
            "Approximate size to download 999.7 MB\n"
          ]
        }
      ],
      "source": [
        "binary_to_image = BinaryToImage()\\\n",
        "    .setOutputCol(\"image\") \\\n",
        "    .setImageType(ImageType.TYPE_3BYTE_BGR)\n",
        "\n",
        "chart_to_text = ChartToTextTable()\\\n",
        "    .pretrained(\"chart_to_text_deplot_jsl\", \"en\", \"clinical/ocr\")\\\n",
        "    .setInputCol([\"image\"])\\\n",
        "    .setOutputCol(\"answers\")\\\n",
        "    .setUseCaching(False)\n",
        "\n",
        "# OCR pipeline\n",
        "pipeline = PipelineModel(stages=[\n",
        "    binary_to_image,\n",
        "    chart_to_text\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08330045",
      "metadata": {
        "id": "08330045"
      },
      "source": [
        "### Load test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7zmwFz8N2exG",
      "metadata": {
        "id": "7zmwFz8N2exG"
      },
      "outputs": [],
      "source": [
        "test_image_path = './data/charts/chart1.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2289a04e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2289a04e",
        "outputId": "9d987958-4a06-4262-d478-a1cd50c99f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+--------------------+\n",
            "|                path|    modificationTime|length|             content|\n",
            "+--------------------+--------------------+------+--------------------+\n",
            "|file:/content/dat...|2024-04-04 16:47:...| 16697|[89 50 4E 47 0D 0...|\n",
            "+--------------------+--------------------+------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import pkg_resources\n",
        "bin_df = spark.read.format(\"binaryFile\").load(test_image_path)\n",
        "bin_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f6dcbf7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "f6dcbf7c",
        "outputId": "4581e232-7789-4fcc-93ab-7a7654ee5187",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Image #0:\n",
            "    Origin: file:/content/data/charts/chart1.png\n",
            "    Resolution: 0 dpi\n",
            "    Width: 1000 px\n",
            "    Height: 685 px\n",
            "    Mode: ImageType.TYPE_BYTE_GRAY\n",
            "    Number of channels: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1000x685>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": 600
          }
        }
      ],
      "source": [
        "image_df = BinaryToImage().transform(bin_df)\n",
        "display_images(image_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898e616c",
      "metadata": {
        "id": "898e616c"
      },
      "source": [
        "## Call pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eb7bd9d8",
      "metadata": {
        "id": "eb7bd9d8"
      },
      "outputs": [],
      "source": [
        "results = pipeline.transform(bin_df).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "547803b0-50b7-4656-a638-e62d1a8150c1",
      "metadata": {
        "id": "547803b0-50b7-4656-a638-e62d1a8150c1",
        "outputId": "51e90e74-07a2-4462-85ab-ef0a028a00c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- image: struct (nullable = true)\n",
            " |    |-- origin: string (nullable = true)\n",
            " |    |-- height: integer (nullable = false)\n",
            " |    |-- width: integer (nullable = false)\n",
            " |    |-- nChannels: integer (nullable = false)\n",
            " |    |-- mode: integer (nullable = false)\n",
            " |    |-- resolution: integer (nullable = false)\n",
            " |    |-- data: binary (nullable = true)\n",
            " |-- exception: string (nullable = true)\n",
            " |-- path: string (nullable = true)\n",
            " |-- modificationTime: timestamp (nullable = true)\n",
            " |-- length: long (nullable = true)\n",
            " |-- pagenum: integer (nullable = true)\n",
            " |-- answers: struct (nullable = true)\n",
            " |    |-- questions: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- answers: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- scores: array (nullable = true)\n",
            " |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "SfcDQ76VHYmB",
      "metadata": {
        "id": "SfcDQ76VHYmB"
      },
      "outputs": [],
      "source": [
        "result = results.select(results.answers.answers).first()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results from Deplot"
      ],
      "metadata": {
        "id": "uNsC40EGC6cV"
      },
      "id": "uNsC40EGC6cV"
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "lQGuFpluC0yZ",
        "outputId": "0ce45a48-a14e-454d-8e46-6ac58a987e38"
      },
      "id": "lQGuFpluC0yZ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  TITLE | Percentage of the U.S. Population Living with a Prior Diagnosis of Cancer, by Current Age<0x0A>AGE RANGE | MALE | FEMALE<0x0A>20-50 | 0.80 | 1.10<0x0A>50-64 | 6.10 | 8.10<0x0A>65-74 | 16.40 | 15.10<0x0A>75-84 | 26.60 | 20.30<0x0A>85+ | 42.60 | 31.90'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM part: explaining the Deplot chart results using LLAMA2-7B"
      ],
      "metadata": {
        "id": "qao8OSMUcE4S"
      },
      "id": "qao8OSMUcE4S"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0avf7xx2lcj",
        "outputId": "dce9caef-22fc-40b7-9e6a-a08ea79c64fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python==0.1.78\n",
            "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting setuptools>=42\n",
            "    Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 821.5/821.5 kB 5.4 MB/s eta 0:00:00\n",
            "  Collecting scikit-build>=0.13\n",
            "    Downloading scikit_build-0.17.6-py3-none-any.whl (84 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.3/84.3 kB 10.2 MB/s eta 0:00:00\n",
            "  Collecting cmake>=3.18\n",
            "    Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.6/26.6 MB 20.0 MB/s eta 0:00:00\n",
            "  Collecting ninja\n",
            "    Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 32.0 MB/s eta 0:00:00\n",
            "  Collecting distro (from scikit-build>=0.13)\n",
            "    Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "  Collecting packaging (from scikit-build>=0.13)\n",
            "    Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 4.9 MB/s eta 0:00:00\n",
            "  Collecting tomli (from scikit-build>=0.13)\n",
            "    Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Collecting wheel>=0.32.0 (from scikit-build>=0.13)\n",
            "    Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.8/65.8 kB 7.7 MB/s eta 0:00:00\n",
            "  Installing collected packages: ninja, wheel, tomli, setuptools, packaging, distro, cmake, scikit-build\n",
            "    Creating /tmp/pip-build-env-16xvvoek/overlay/local/bin\n",
            "    changing mode of /tmp/pip-build-env-16xvvoek/overlay/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-16xvvoek/overlay/local/bin/wheel to 755\n",
            "    changing mode of /tmp/pip-build-env-16xvvoek/overlay/local/bin/distro to 755\n",
            "    changing mode of /tmp/pip-build-env-16xvvoek/overlay/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-16xvvoek/overlay/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-16xvvoek/overlay/local/bin/ctest to 755\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "  torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "  torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "  torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "  Successfully installed cmake-3.29.0.1 distro-1.9.0 ninja-1.11.1.1 packaging-24.0 scikit-build-0.17.6 setuptools-69.2.0 tomli-2.0.1 wheel-0.43.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  running egg_info\n",
            "  writing llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
            "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  running dist_info\n",
            "  creating /tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info\n",
            "  writing /tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file '/tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  creating '/tmp/pip-modern-metadata-n6ym1kxa/llama_cpp_python-0.1.78.dist-info'\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.23.4\n",
            "  Downloading numpy-1.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python==0.1.78)\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m230.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "\n",
            "\n",
            "  --------------------------------------------------------------------------------\n",
            "  -- Trying 'Ninja' generator\n",
            "  --------------------------------\n",
            "  ---------------------------\n",
            "  ----------------------\n",
            "  -----------------\n",
            "  ------------\n",
            "  -------\n",
            "  --\n",
            "  CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "    CMake.\n",
            "\n",
            "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "    CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "  Not searching for unused variables given on the command line.\n",
            "\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Configuring done (0.8s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_cmake_test_compile/build\n",
            "  --\n",
            "  -------\n",
            "  ------------\n",
            "  -----------------\n",
            "  ----------------------\n",
            "  ---------------------------\n",
            "  --------------------------------\n",
            "  -- Trying 'Ninja' generator - success\n",
            "  --------------------------------------------------------------------------------\n",
            "\n",
            "  Configuring Project\n",
            "    Working directory:\n",
            "      /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-build\n",
            "    Command:\n",
            "      /tmp/pip-build-env-16xvvoek/overlay/local/lib/python3.10/dist-packages/cmake/data/bin/cmake /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c -G Ninja -DCMAKE_MAKE_PROGRAM:FILEPATH=/tmp/pip-build-env-16xvvoek/overlay/local/lib/python3.10/dist-packages/ninja/data/bin/ninja --no-warn-unused-cli -DCMAKE_INSTALL_PREFIX:PATH=/tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install -DPYTHON_VERSION_STRING:STRING=3.10.12 -DSKBUILD:INTERNAL=TRUE -DCMAKE_MODULE_PATH:PATH=/tmp/pip-build-env-16xvvoek/overlay/local/lib/python3.10/dist-packages/skbuild/resources/cmake -DPYTHON_EXECUTABLE:PATH=/usr/bin/python3 -DPYTHON_INCLUDE_DIR:PATH=/usr/include/python3.10 -DPYTHON_LIBRARY:PATH=/usr/lib/x86_64-linux-gnu/libpython3.10.so -DPython_EXECUTABLE:PATH=/usr/bin/python3 -DPython_ROOT_DIR:PATH=/usr -DPython_FIND_REGISTRY:STRING=NEVER -DPython_INCLUDE_DIR:PATH=/usr/include/python3.10 -DPython3_EXECUTABLE:PATH=/usr/bin/python3 -DPython3_ROOT_DIR:PATH=/usr -DPython3_FIND_REGISTRY:STRING=NEVER -DPython3_INCLUDE_DIR:PATH=/usr/include/python3.10 -DCMAKE_MAKE_PROGRAM:FILEPATH=/tmp/pip-build-env-16xvvoek/overlay/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -DLLAMA_CUBLAS=on -DCMAKE_BUILD_TYPE:STRING=Release -DLLAMA_CUBLAS=on\n",
            "\n",
            "  Not searching for unused variables given on the command line.\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  CMake Warning at vendor/llama.cpp/CMakeLists.txt:117 (message):\n",
            "    Git repository not found; to enable automatic generation of build info,\n",
            "    make sure Git is installed and the project is a Git repository.\n",
            "\n",
            "\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.2.140\")\n",
            "  -- cuBLAS found\n",
            "  -- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  -- Configuring done (4.2s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-build\n",
            "  [1/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o\n",
            "  [2/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/k_quants.c.o\n",
            "  [3/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o\n",
            "  [4/9] Building CXX object vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o\n",
            "  [5/9] Building CUDA object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [6/9] Linking CXX shared library vendor/llama.cpp/libllama.so\n",
            "  [7/9] Linking CUDA shared library vendor/llama.cpp/libggml_shared.so\n",
            "  [8/9] Linking CUDA static library vendor/llama.cpp/libggml_static.a\n",
            "  [8/9] Install the project...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/lib/libggml_shared.so\n",
            "  -- Installing: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/bin/convert.py\n",
            "  -- Installing: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/bin/convert-lora-to-ggml.py\n",
            "  -- Installing: /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/_skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so\" to \"\"\n",
            "\n",
            "  copying llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py\n",
            "  copying llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py\n",
            "  copying llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py\n",
            "  copying llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py\n",
            "  copying llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py\n",
            "  copying llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py\n",
            "  creating directory _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server\n",
            "  copying llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py\n",
            "  copying llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py\n",
            "  copying llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py\n",
            "  copying /tmp/pip-install-0kz4kgc7/llama-cpp-python_845a4232fac64a4c9b7e984c11ca356c/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/py.typed\n",
            "\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copied 9 files\n",
            "  running build_ext\n",
            "  installing to _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copied 11 files\n",
            "  running install_data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/lib/libggml_shared.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/bin/convert-lora-to-ggml.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/bin/convert.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
            "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  Copying llama_cpp_python.egg-info to _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  copied 0 files\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-if6gn8ql/.tmp-nvv37ioa/llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl' and adding '_skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'llama_cpp/__init__.py'\n",
            "  adding 'llama_cpp/libllama.so'\n",
            "  adding 'llama_cpp/llama.py'\n",
            "  adding 'llama_cpp/llama_cpp.py'\n",
            "  adding 'llama_cpp/llama_grammar.py'\n",
            "  adding 'llama_cpp/llama_types.py'\n",
            "  adding 'llama_cpp/py.typed'\n",
            "  adding 'llama_cpp/utils.py'\n",
            "  adding 'llama_cpp/server/__init__.py'\n",
            "  adding 'llama_cpp/server/__main__.py'\n",
            "  adding 'llama_cpp/server/app.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert-lora-to-ggml.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/lib/libggml_shared.so'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/lib/libllama.so'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/LICENSE.md'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/METADATA'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/WHEEL'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/top_level.txt'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/RECORD'\n",
            "  removing _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl size=5811096 sha256=260b3fe136d2f554dd80308a39493e37b459cea383b3898d44ed653f20afa8ab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v1emp57v/wheels/61/f9/20/9ca660a9d3f2a47e44217059409478865948b5c8a1cba70030\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.10.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/bin/f2py3\n",
            "      Removing file or directory /usr/local/bin/f2py3.10\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.24.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "  changing mode of /usr/local/bin/f2py3 to 755\n",
            "  changing mode of /usr/local/bin/f2py3.10 to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.4 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.1.78 numpy-1.23.4 typing-extensions-4.10.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Requirement already satisfied: llama-cpp-python==0.1.78 in /usr/local/lib/python3.10/dist-packages (0.1.78)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (1.23.4)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (5.6.3)\n",
            "Requirement already satisfied: numpy==1.23.4 in /usr/local/lib/python3.10/dist-packages (1.23.4)\n"
          ]
        }
      ],
      "source": [
        "# GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
        "!pip install huggingface_hub\n",
        "!pip install llama-cpp-python==0.1.78\n",
        "!pip install numpy==1.23.4"
      ],
      "id": "L0avf7xx2lcj"
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "\n",
        "model_name_or_path = \"TheBloke/Llama-2-7B-chat-GGML\"\n",
        "model_basename = \"llama-2-7b-chat.ggmlv3.q5_1.bin\"\n",
        "\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "id": "qJ90LnMv54Y-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "c5422bff0c4f4d51ad70c97c9e253da3",
            "84a07180714645fabc926b57fda1dab0",
            "81d4c91d0dbc49f18926974e0128415c",
            "d6a75ed11cf6463da6ce9d5f19c2c9ef",
            "23bf241a26ea4521acf79ee012059409",
            "cadeaa0c87a741a6a90d83f202711f44",
            "4c7ebe2b4d5d43c1ba4d8eff6272657c",
            "f2c4777a2511474a961d7e3418d6bfc3",
            "5b3d0c8fd9b9491b948fef4791e8b717",
            "cebd9f6e6866401da66e8ed97e8744c5",
            "936b7541e2a4428387a9c33497ef11fd"
          ]
        },
        "outputId": "8573c1f1-90ab-4019-e40b-cebcb3ae53e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-7b-chat.ggmlv3.q5_1.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5422bff0c4f4d51ad70c97c9e253da3"
            }
          },
          "metadata": {}
        }
      ],
      "id": "qJ90LnMv54Y-"
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU params set\n",
        "lcpp_llm = None\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2,\n",
        "    n_batch=3000,\n",
        "    n_gpu_layers=32\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irftToUj6aWt",
        "outputId": "31504aee-2b4b-4326-ae62-ec32e41dcc8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "id": "irftToUj6aWt"
    },
    {
      "cell_type": "code",
      "source": [
        "# See the number of layers in GPU\n",
        "lcpp_llm.params.n_gpu_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG4Pylz662At",
        "outputId": "c7a77044-8a5e-4a6c-db48-63a6a5fdbea9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "id": "YG4Pylz662At"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input variables\n",
        "chart = result[0]\n",
        "# Conversation template\n",
        "prompt_template = f'''SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
        "\n",
        "USER: you are an expert in explaining charts. Can you please interpret as much as you can, the following information regarding a chart? \"{chart}\"\n",
        "\n",
        "ASSISTANT:\n",
        "'''\n",
        "\n",
        "# Print the conversation template\n",
        "print(prompt_template)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLiwK61MXtJh",
        "outputId": "3b2b6b98-c812-4c27-c571-cbd0b140e19e"
      },
      "id": "DLiwK61MXtJh",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
            "\n",
            "USER: you are an expert in explaining charts. Can you please interpret as much as you can, the following information regarding a chart? \"  TITLE | Percentage of the U.S. Population Living with a Prior Diagnosis of Cancer, by Current Age<0x0A>AGE RANGE | MALE | FEMALE<0x0A>20-50 | 0.80 | 1.10<0x0A>50-64 | 6.10 | 8.10<0x0A>65-74 | 16.40 | 15.10<0x0A>75-84 | 26.60 | 20.30<0x0A>85+ | 42.60 | 31.90\"\n",
            "\n",
            "ASSISTANT:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
        "                  repeat_penalty=1.2, top_k=150,\n",
        "                  echo=True)"
      ],
      "metadata": {
        "id": "0aF0qWUJ7OPK"
      },
      "execution_count": 25,
      "outputs": [],
      "id": "0aF0qWUJ7OPK"
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlJ1JgR68DDO",
        "outputId": "362935c9-706c-405a-b364-95878d2ab06a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-7fb5826f-5475-4430-a825-1bb01cdd24c2', 'object': 'text_completion', 'created': 1712250153, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-chat-GGML/snapshots/76cd63c351ae389e1d4b91cab2cf470aab11864b/llama-2-7b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': 'SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\nUSER: you are an expert in explaining charts. Can you please interpret as much as you can, the following information regarding a chart? \"  TITLE | Percentage of the U.S. Population Living with a Prior Diagnosis of Cancer, by Current Age<0x0A>AGE RANGE | MALE | FEMALE<0x0A>20-50 | 0.80 | 1.10<0x0A>50-64 | 6.10 | 8.10<0x0A>65-74 | 16.40 | 15.10<0x0A>75-84 | 26.60 | 20.30<0x0A>85+ | 42.60 | 31.90\"\\n\\nASSISTANT:\\nOf course, I\\'d be happy to help you interpret the chart! The chart shows the percentage of the U.S. population living with a prior diagnosis of cancer, by current age group. Here are some key takeaways from the chart:\\n\\n* For people aged 20-50, approximately 8% of males and 11% of females have been diagnosed with cancer.\\n* Among those aged 50-64, the percentage of both males and females with a prior cancer diagnosis increases to around 61% for males and 81% for females.\\n* The 65-74 age group sees a significant jump in the number of people living with a previous cancer diagnosis - approximately 16% of males and 20% of females have been affected.\\n* For those aged 75-84, the percentage of both genders with a prior cancer diagnosis decreases slightly to around 27% for males and 32% for females.\\n* Finally, among those aged 85+, approximately 43% of males and 33% of females have been diagnosed with cancer at some point in their lives.\\n', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 225, 'completion_tokens': 256, 'total_tokens': 481}}\n"
          ]
        }
      ],
      "id": "jlJ1JgR68DDO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLAMA2 interpretation results"
      ],
      "metadata": {
        "id": "8iJPVnPHDzxp"
      },
      "id": "8iJPVnPHDzxp"
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"].split(\"ASSISTANT:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qona58gX8oAn",
        "outputId": "bf9fc71e-e7bd-42d9-dba5-5cdc1e828fd3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Of course, I'd be happy to help you interpret the chart! The chart shows the percentage of the U.S. population living with a prior diagnosis of cancer, by current age group. Here are some key takeaways from the chart:\n",
            "\n",
            "* For people aged 20-50, approximately 8% of males and 11% of females have been diagnosed with cancer.\n",
            "* Among those aged 50-64, the percentage of both males and females with a prior cancer diagnosis increases to around 61% for males and 81% for females.\n",
            "* The 65-74 age group sees a significant jump in the number of people living with a previous cancer diagnosis - approximately 16% of males and 20% of females have been affected.\n",
            "* For those aged 75-84, the percentage of both genders with a prior cancer diagnosis decreases slightly to around 27% for males and 32% for females.\n",
            "* Finally, among those aged 85+, approximately 43% of males and 33% of females have been diagnosed with cancer at some point in their lives.\n",
            "\n"
          ]
        }
      ],
      "id": "Qona58gX8oAn"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "7631773df7a20f76ce0129852d6286a048d5c426a0098a673052d93f81596669"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5422bff0c4f4d51ad70c97c9e253da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84a07180714645fabc926b57fda1dab0",
              "IPY_MODEL_81d4c91d0dbc49f18926974e0128415c",
              "IPY_MODEL_d6a75ed11cf6463da6ce9d5f19c2c9ef"
            ],
            "layout": "IPY_MODEL_23bf241a26ea4521acf79ee012059409"
          }
        },
        "84a07180714645fabc926b57fda1dab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cadeaa0c87a741a6a90d83f202711f44",
            "placeholder": "​",
            "style": "IPY_MODEL_4c7ebe2b4d5d43c1ba4d8eff6272657c",
            "value": "llama-2-7b-chat.ggmlv3.q5_1.bin: 100%"
          }
        },
        "81d4c91d0dbc49f18926974e0128415c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c4777a2511474a961d7e3418d6bfc3",
            "max": 5055128192,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b3d0c8fd9b9491b948fef4791e8b717",
            "value": 5055128192
          }
        },
        "d6a75ed11cf6463da6ce9d5f19c2c9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cebd9f6e6866401da66e8ed97e8744c5",
            "placeholder": "​",
            "style": "IPY_MODEL_936b7541e2a4428387a9c33497ef11fd",
            "value": " 5.06G/5.06G [01:24&lt;00:00, 128MB/s]"
          }
        },
        "23bf241a26ea4521acf79ee012059409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cadeaa0c87a741a6a90d83f202711f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7ebe2b4d5d43c1ba4d8eff6272657c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c4777a2511474a961d7e3418d6bfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3d0c8fd9b9491b948fef4791e8b717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cebd9f6e6866401da66e8ed97e8744c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936b7541e2a4428387a9c33497ef11fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}