{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc60aeec",
   "metadata": {},
   "source": [
    "# Visual Document NER v2 FineTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28ce46",
   "metadata": {},
   "source": [
    "## Install spark-ocr python packge\n",
    "\n",
    "Need specify path to spark-ocr-assembly-[version].jar or secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb134c",
   "metadata": {},
   "source": [
    "### To simulate the build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b GH337_LayoutLMv2NER_Finetune --recurse-submodules https://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@github.com/JohnSnowLabs/spark-ocr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = \"\"\n",
    "license = \"\"\n",
    "version = secret.split(\"-\")[0]\n",
    "AWS_ACCESS_KEY_ID = \"\"\n",
    "AWS_SECRET_ACCESS_KEY = \"\"\n",
    "spark_ocr_jar_path = \"../../target/scala-2.11\"\n",
    "\n",
    "import os\n",
    "os.environ['JSL_OCR_LICENSE'] = license\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc382c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88b0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spark-ocr==$version+spark30 --extra-index-url=https://pypi.johnsnowlabs.com/$secret --upgrade\n",
    "# !pip install ../../python/dist/spark-ocr-3.9.0+spark30.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"spark-ocr/python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sparkocr\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.utils import display_images\n",
    "from sparkocr.enums import *\n",
    "\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05d084",
   "metadata": {},
   "source": [
    "### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49583b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkocr import start\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = start(jar_path = spark_ocr_jar_path)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414f039",
   "metadata": {},
   "source": [
    "## Load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "test_image_path = pkg_resources.resource_filename('sparkocr', 'resources/ocr/forms')\n",
    "bin_df = spark.read.format(\"binaryFile\").load(test_image_path)\n",
    "bin_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329ed17",
   "metadata": {},
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5543fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = BinaryToImage().transform(bin_df)\n",
    "display_images(image_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d696b06",
   "metadata": {},
   "source": [
    "## Prepare Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_to_image = BinaryToImage()\\\n",
    "    .setOutputCol(\"image\") \\\n",
    "    .setImageType(ImageType.TYPE_3BYTE_BGR)\n",
    "\n",
    "img_to_hocr = ImageToHocr()\\\n",
    "    .setInputCol(\"image\")\\\n",
    "    .setOutputCol(\"hocr\")\\\n",
    "    .setIgnoreResolution(False)\\\n",
    "    .setOcrParams([\"preserve_interword_spaces=0\"])\n",
    "\n",
    "tokenizer = HocrTokenizer()\\\n",
    "    .setInputCol(\"hocr\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "doc_ner = VisualDocumentNerV2()\\\n",
    "    .pretrained(\"layoutlmv2_funsd\", \"en\", \"clinical/ocr\")\\\n",
    "    .setInputCols([\"token\", \"image\"])\\\n",
    "    .setOutputCol(\"entities\")\\\n",
    "    .setWhiteList([\"other\", \"b-header\", \"i-header\", \"b-question\", \"i-question\", \"b-answer\", \"i-answer\"])\n",
    "\n",
    "draw = ImageDrawAnnotations() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setInputChunksCol(\"entities\") \\\n",
    "    .setOutputCol(\"image_with_annotations\") \\\n",
    "    .setFontSize(10) \\\n",
    "    .setLineWidth(4)\\\n",
    "    .setRectColor(Color.red)\n",
    "\n",
    "# OCR pipeline\n",
    "pipeline = PipelineModel(stages=[\n",
    "    binary_to_image,\n",
    "    img_to_hocr,\n",
    "    tokenizer,\n",
    "    doc_ner,\n",
    "    draw\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806ccb9",
   "metadata": {},
   "source": [
    "## Prepare Pyspark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipeline.transform(bin_df).cache()\n",
    "## since pyspark2.3 doesn't have element_at, 'getItem' is involked\n",
    "path_array = f.split(results['path'], '/')\n",
    "\n",
    "# from pyspark2.4\n",
    "# results.withColumn(\"filename\", f.element_at(f.split(\"path\", \"/\"), -1)) \\\n",
    "\n",
    "results.withColumn('filename', path_array.getItem(f.size(path_array)- 1)) \\\n",
    "    .withColumn(\"exploded_entities\", f.explode(\"entities\")) \\\n",
    "    .select(\"filename\", \"exploded_entities\") \\\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a3d44",
   "metadata": {},
   "source": [
    "### Define VisualDocumentNerV2 instance object for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ner = VisualDocumentNerV2()\\\n",
    "    .setInputCols([\"token\", \"image\"])\\\n",
    "    .setOutputCol(\"entities\")\\\n",
    "    .setWhiteList([\"other\", \"b-header\", \"i-header\", \"b-question\", \"i-question\", \"b-answer\", \"i-answer\"])\\\n",
    "    .setbatchSize(4)\\\n",
    "    .setShuffleBatchTraining(True)\\\n",
    "    .setmodelNameOrPath(\"nielsr/layoutlmv2-finetuned-funsd\")\\\n",
    "    .setvocabPath(\"sparkocr/resources/models/layoutlm/LayoutLM.v2.voc.txt\")\\\n",
    "    .setcudeDevice('cuda:0')\\\n",
    "    .setnumTrainEpochs(3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a2f40",
   "metadata": {},
   "source": [
    "### Calling fit method for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nerv2 = doc_ner.fit(pyspark_dataframe=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e7e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nerv2.saveModel(model_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b6994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
