{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118414e6",
   "metadata": {},
   "source": [
    "## Fine Tuning of Dit Based Visual Document Classifier on Rvl Cdip\n",
    "### 1. Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fe9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade spark-ocr==5.0.1 --user --extra-index-url https://pypi.johnsnowlabs.com/SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311c3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkocr.transformers import *\n",
    "from sparkocr.transformers.readers.rvlcdip_reader import RvlCdipReader\n",
    "from sparkocr import start\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0655d99-3b97-46fb-b6f2-b8ddd605c5fe",
   "metadata": {},
   "source": [
    "### 2. Start Spark session\n",
    "Define some Spark configs first,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2431044d-38d0-419c-a90c-fb2a7aa4bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extras = {\"spark.driver.maxResultSize\":\"3500m\",\n",
    "          \"spark.kryoserializer.buffer.max\": \"1000M\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d7680-ca57-4677-bbe3-61b52313df5f",
   "metadata": {},
   "source": [
    "#### 2.1 Optional: Setup S3 access\n",
    "If you are hosting your dataset on S3 you will need to access your S3 bucket. Run the following cells to add the right dependencies according to your Spark version.\n",
    "Skip next cell if using another storage option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de2adf6-0af8-42dc-81e7-5530c5f28048",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_to_aws_hadoop = {\"3.0\": \"2.7.4\", \"3.1\": \"3.2.0\", \"3.2\": \"3.3.1\", \"3.3\": \"3.3.2\", \"3.4\":\"3.3.4\"}\n",
    "spark_version = pyspark.__version__[:3]\n",
    "aws_version = spark_to_aws_hadoop[spark_version]\n",
    "\n",
    "extras[\"spark.jars.packages\"] = \"org.apache.hadoop:hadoop-aws:\"+aws_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df17751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.2.1\n",
      "Spark NLP version: 5.0.2\n",
      "Spark OCR version: 5.0.1rc2\n",
      "\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5e5c0cd2-30e6-4ecd-a8ab-acc30a0139f4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.0.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.15.0 in central\n",
      ":: resolution report :: resolve 1085ms :: artifacts dl 25ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.0.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.15.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 by [com.amazonaws#aws-java-sdk-bundle;1.11.901] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   78  |   0   |   0   |   4   ||   74  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5e5c0cd2-30e6-4ecd-a8ab-acc30a0139f4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 74 already retrieved (0kB/16ms)\n",
      "23/09/15 17:38:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/15 17:38:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = start(jar_path=\"../\",\n",
    "              extra_conf=extras)\n",
    "\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4a468-53dc-4c4d-8a7e-9112bce16c25",
   "metadata": {},
   "source": [
    "### 3. Load the Training Dataset\n",
    "Let's use VisualNLP RvlCdipReader's utility functions to lift the RvlCdip training dataset. Let's take a look at the documentation to understand different parameters and options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eef2ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method readTrainDataset in module sparkocr.transformers.readers.rvlcdip_reader:\n",
      "\n",
      "readTrainDataset(spark, labels_path, images_path, partitions=8, storage_level=StorageLevel(True, False, False, False, 1)) method of sparkocr.transformers.readers.rvlcdip_reader.RvlCdipReader instance\n",
      "    Reads the dataset from an external resource.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    spark : :class:`pyspark.sql.SparkSession`\n",
      "        Initiated Spark Session with Spark NLP\n",
      "    labels_path : str\n",
      "        The path to the labels file, i.e., labels/train.txt\n",
      "    images_path : str\n",
      "        the path where you unzipped the files for RvlCdip Train Images\n",
      "     partitions : int\n",
      "        sets the minimum number of partitions for the case of lifting multiple files in parallel into a single dataframe. Defaults to 8.\n",
      "    storage_level : sets the persistence level according to PySpark definitions. Defaults to StorageLevel.DISK_ONLY.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RvlCdipReader().readTrainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f9011",
   "metadata": {},
   "source": [
    "So, we need to provide 2 paths, one to the labels file, and another one to the images file. In this case, we have previously flattened all the images into a single folder, to make the data access faster in Spark. This is not mandatory, but recommended in filesystems where listing folders is expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3892b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = \"s3a://dev.johnsnowlabs.com/ocr/datasets/rvl_cdip_train_labels.txt\"\n",
    "images_path = \"s3a://dev.johnsnowlabs.com/ocr/datasets/rvl_cdip_full_/*.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461dd1e-cd3d-4d53-bb86-ccc05bfd42be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/15 14:25:41 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "[Stage 1:==========>                                         (2037 + 8) / 10000]\r"
     ]
    }
   ],
   "source": [
    "train_df = RvlCdipReader().readTrainDataset(spark, labels_path, images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a0836",
   "metadata": {},
   "source": [
    "### 3.1 Optional: create a smaller local copy to play with different paramers.\n",
    "You don't need to work with the entire dataset all the time, and until you properly set up all the parameters for fine-tuning, it is recommended to work on a smaller subset of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d0a31b-b609-4f87-98bd-82d76aa13f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df.limit(400).write.parquet(\"train_df\")\n",
    "train_df = spark.read.parquet(\"./train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11b567e-eb7c-432a-8e4a-84aa47615217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- act_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d19e361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ddde9",
   "metadata": {},
   "source": [
    "Let's take a look at the different labels present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00272ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resume',\n",
       " 'handwritten',\n",
       " 'memo',\n",
       " 'email',\n",
       " 'questionnaire',\n",
       " 'scientific_report',\n",
       " 'invoice',\n",
       " 'advertisement',\n",
       " 'news_article',\n",
       " 'form',\n",
       " 'scientific_publication',\n",
       " 'file_folder',\n",
       " 'budget',\n",
       " 'specification',\n",
       " 'presentation',\n",
       " 'letter']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = RvlCdipReader()._labels\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29080710",
   "metadata": {},
   "source": [
    "### 4. Training Pipeline and Model\n",
    "In this section, we will define the necessary transformers to use in the fine-tuning process. </br>\n",
    "BinaryToImage: will convert the binary content into an image structure containing information about the image such as resolution, channels, etc.<br>\n",
    "VisualDocumentaClassifierV3: This one is our model. We're defining training parameters like the number of epochs, the labels, or the batch size.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46be5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_to_image = BinaryToImage().\\\n",
    "    setOutputCol(\"image\")\n",
    "\n",
    "classifier = VisualDocumentClassifierV3() \\\n",
    "            .setInputCols([\"image\"]) \\\n",
    "            .setOutputCol(\"entities\") \\\n",
    "            .setInputCols([\"image\", \"act_label\"]) \\\n",
    "            .setOutputCol(\"entities\") \\\n",
    "            .setLabels(labels) \\\n",
    "            .setTrainBatchSize(32) \\\n",
    "            .setTrainEpochs(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef09f0",
   "metadata": {},
   "source": [
    "Let's add the 'image' column to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa326d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = false)\n",
      " |    |-- width: integer (nullable = false)\n",
      " |    |-- nChannels: integer (nullable = false)\n",
      " |    |-- mode: integer (nullable = false)\n",
      " |    |-- resolution: integer (nullable = false)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- exception: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- act_label: string (nullable = true)\n",
      " |-- pagenum: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_labels = binary_to_image.transform(train_df)\n",
    "images_labels.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc1df6-44cd-436a-9f25-1f99623cd908",
   "metadata": {},
   "source": [
    "### 4.1 Optional: dataset cleanup\n",
    "Sometimes encoding issues appear on some files, we can just delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2ffb9-8be0-4000-9804-acac76462538",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_labels.filter(images_labels[\"image\"].isNull() == True).select(\"path\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160d8b9",
   "metadata": {},
   "source": [
    "### 5.1 Trigger fine-tuning and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4481ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/cache_pretrained/ocr/base/dit-base-224-p16-500k-62d53a.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "17:39:38, INFO Patch size = (16, 16)\n",
      "17:39:38, INFO Load ckpt from /root/cache_pretrained/ocr/base/dit-base-224-p16-500k-62d53a.pth\n",
      "17:39:38, INFO Load state_dict by model_key = model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of Beit not initialized from pretrained model: ['blocks.0.attn.relative_position_bias_table', 'blocks.1.attn.relative_position_bias_table', 'blocks.2.attn.relative_position_bias_table', 'blocks.3.attn.relative_position_bias_table', 'blocks.4.attn.relative_position_bias_table', 'blocks.5.attn.relative_position_bias_table', 'blocks.6.attn.relative_position_bias_table', 'blocks.7.attn.relative_position_bias_table', 'blocks.8.attn.relative_position_bias_table', 'blocks.9.attn.relative_position_bias_table', 'blocks.10.attn.relative_position_bias_table', 'blocks.11.attn.relative_position_bias_table']\n",
      "Weights from pretrained model not used in Beit: ['pos_embed']\n",
      "Ignored weights of Beit not initialized from pretrained model: ['blocks.0.attn.relative_position_index', 'blocks.1.attn.relative_position_index', 'blocks.2.attn.relative_position_index', 'blocks.3.attn.relative_position_index', 'blocks.4.attn.relative_position_index', 'blocks.5.attn.relative_position_index', 'blocks.6.attn.relative_position_index', 'blocks.7.attn.relative_position_index', 'blocks.8.attn.relative_position_index', 'blocks.9.attn.relative_position_index', 'blocks.10.attn.relative_position_index', 'blocks.11.attn.relative_position_index']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:39:39, INFO Model = Beit(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1-11): 11 x Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): Identity()\n",
      "  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=16, bias=True)\n",
      ")\n",
      "17:39:39, INFO number of params:85774288\n",
      "17:39:39, INFO Dit model Training.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR = 0.00050000\n",
      "Batch size = 64\n",
      "Update frequent = 2\n",
      "Number of training examples = 253\n",
      "Number of training training per epoch = 3\n",
      "Assigned values = [0.023757264018058777, 0.03167635202407837, 0.04223513603210449, 0.056313514709472656, 0.07508468627929688, 0.1001129150390625, 0.13348388671875, 0.177978515625, 0.2373046875, 0.31640625, 0.421875, 0.5625, 0.75, 1.0]\n",
      "Param groups = {\n",
      "  \"layer_0_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"cls_token\",\n",
      "      \"patch_embed.proj.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.023757264018058777\n",
      "  },\n",
      "  \"layer_0_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"patch_embed.proj.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.023757264018058777\n",
      "  },\n",
      "  \"layer_1_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.0.gamma_1\",\n",
      "      \"blocks.0.gamma_2\",\n",
      "      \"blocks.0.norm1.weight\",\n",
      "      \"blocks.0.norm1.bias\",\n",
      "      \"blocks.0.attn.q_bias\",\n",
      "      \"blocks.0.attn.v_bias\",\n",
      "      \"blocks.0.attn.relative_position_bias_table\",\n",
      "      \"blocks.0.attn.proj.bias\",\n",
      "      \"blocks.0.norm2.weight\",\n",
      "      \"blocks.0.norm2.bias\",\n",
      "      \"blocks.0.mlp.fc1.bias\",\n",
      "      \"blocks.0.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.03167635202407837\n",
      "  },\n",
      "  \"layer_1_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.0.attn.qkv.weight\",\n",
      "      \"blocks.0.attn.proj.weight\",\n",
      "      \"blocks.0.mlp.fc1.weight\",\n",
      "      \"blocks.0.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.03167635202407837\n",
      "  },\n",
      "  \"layer_2_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.1.gamma_1\",\n",
      "      \"blocks.1.gamma_2\",\n",
      "      \"blocks.1.norm1.weight\",\n",
      "      \"blocks.1.norm1.bias\",\n",
      "      \"blocks.1.attn.q_bias\",\n",
      "      \"blocks.1.attn.v_bias\",\n",
      "      \"blocks.1.attn.relative_position_bias_table\",\n",
      "      \"blocks.1.attn.proj.bias\",\n",
      "      \"blocks.1.norm2.weight\",\n",
      "      \"blocks.1.norm2.bias\",\n",
      "      \"blocks.1.mlp.fc1.bias\",\n",
      "      \"blocks.1.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.04223513603210449\n",
      "  },\n",
      "  \"layer_2_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.1.attn.qkv.weight\",\n",
      "      \"blocks.1.attn.proj.weight\",\n",
      "      \"blocks.1.mlp.fc1.weight\",\n",
      "      \"blocks.1.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.04223513603210449\n",
      "  },\n",
      "  \"layer_3_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.2.gamma_1\",\n",
      "      \"blocks.2.gamma_2\",\n",
      "      \"blocks.2.norm1.weight\",\n",
      "      \"blocks.2.norm1.bias\",\n",
      "      \"blocks.2.attn.q_bias\",\n",
      "      \"blocks.2.attn.v_bias\",\n",
      "      \"blocks.2.attn.relative_position_bias_table\",\n",
      "      \"blocks.2.attn.proj.bias\",\n",
      "      \"blocks.2.norm2.weight\",\n",
      "      \"blocks.2.norm2.bias\",\n",
      "      \"blocks.2.mlp.fc1.bias\",\n",
      "      \"blocks.2.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.056313514709472656\n",
      "  },\n",
      "  \"layer_3_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.2.attn.qkv.weight\",\n",
      "      \"blocks.2.attn.proj.weight\",\n",
      "      \"blocks.2.mlp.fc1.weight\",\n",
      "      \"blocks.2.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.056313514709472656\n",
      "  },\n",
      "  \"layer_4_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.3.gamma_1\",\n",
      "      \"blocks.3.gamma_2\",\n",
      "      \"blocks.3.norm1.weight\",\n",
      "      \"blocks.3.norm1.bias\",\n",
      "      \"blocks.3.attn.q_bias\",\n",
      "      \"blocks.3.attn.v_bias\",\n",
      "      \"blocks.3.attn.relative_position_bias_table\",\n",
      "      \"blocks.3.attn.proj.bias\",\n",
      "      \"blocks.3.norm2.weight\",\n",
      "      \"blocks.3.norm2.bias\",\n",
      "      \"blocks.3.mlp.fc1.bias\",\n",
      "      \"blocks.3.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.07508468627929688\n",
      "  },\n",
      "  \"layer_4_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.3.attn.qkv.weight\",\n",
      "      \"blocks.3.attn.proj.weight\",\n",
      "      \"blocks.3.mlp.fc1.weight\",\n",
      "      \"blocks.3.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.07508468627929688\n",
      "  },\n",
      "  \"layer_5_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.4.gamma_1\",\n",
      "      \"blocks.4.gamma_2\",\n",
      "      \"blocks.4.norm1.weight\",\n",
      "      \"blocks.4.norm1.bias\",\n",
      "      \"blocks.4.attn.q_bias\",\n",
      "      \"blocks.4.attn.v_bias\",\n",
      "      \"blocks.4.attn.relative_position_bias_table\",\n",
      "      \"blocks.4.attn.proj.bias\",\n",
      "      \"blocks.4.norm2.weight\",\n",
      "      \"blocks.4.norm2.bias\",\n",
      "      \"blocks.4.mlp.fc1.bias\",\n",
      "      \"blocks.4.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.1001129150390625\n",
      "  },\n",
      "  \"layer_5_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.4.attn.qkv.weight\",\n",
      "      \"blocks.4.attn.proj.weight\",\n",
      "      \"blocks.4.mlp.fc1.weight\",\n",
      "      \"blocks.4.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.1001129150390625\n",
      "  },\n",
      "  \"layer_6_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.5.gamma_1\",\n",
      "      \"blocks.5.gamma_2\",\n",
      "      \"blocks.5.norm1.weight\",\n",
      "      \"blocks.5.norm1.bias\",\n",
      "      \"blocks.5.attn.q_bias\",\n",
      "      \"blocks.5.attn.v_bias\",\n",
      "      \"blocks.5.attn.relative_position_bias_table\",\n",
      "      \"blocks.5.attn.proj.bias\",\n",
      "      \"blocks.5.norm2.weight\",\n",
      "      \"blocks.5.norm2.bias\",\n",
      "      \"blocks.5.mlp.fc1.bias\",\n",
      "      \"blocks.5.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.13348388671875\n",
      "  },\n",
      "  \"layer_6_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.5.attn.qkv.weight\",\n",
      "      \"blocks.5.attn.proj.weight\",\n",
      "      \"blocks.5.mlp.fc1.weight\",\n",
      "      \"blocks.5.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.13348388671875\n",
      "  },\n",
      "  \"layer_7_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.6.gamma_1\",\n",
      "      \"blocks.6.gamma_2\",\n",
      "      \"blocks.6.norm1.weight\",\n",
      "      \"blocks.6.norm1.bias\",\n",
      "      \"blocks.6.attn.q_bias\",\n",
      "      \"blocks.6.attn.v_bias\",\n",
      "      \"blocks.6.attn.relative_position_bias_table\",\n",
      "      \"blocks.6.attn.proj.bias\",\n",
      "      \"blocks.6.norm2.weight\",\n",
      "      \"blocks.6.norm2.bias\",\n",
      "      \"blocks.6.mlp.fc1.bias\",\n",
      "      \"blocks.6.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.177978515625\n",
      "  },\n",
      "  \"layer_7_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.6.attn.qkv.weight\",\n",
      "      \"blocks.6.attn.proj.weight\",\n",
      "      \"blocks.6.mlp.fc1.weight\",\n",
      "      \"blocks.6.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.177978515625\n",
      "  },\n",
      "  \"layer_8_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.7.gamma_1\",\n",
      "      \"blocks.7.gamma_2\",\n",
      "      \"blocks.7.norm1.weight\",\n",
      "      \"blocks.7.norm1.bias\",\n",
      "      \"blocks.7.attn.q_bias\",\n",
      "      \"blocks.7.attn.v_bias\",\n",
      "      \"blocks.7.attn.relative_position_bias_table\",\n",
      "      \"blocks.7.attn.proj.bias\",\n",
      "      \"blocks.7.norm2.weight\",\n",
      "      \"blocks.7.norm2.bias\",\n",
      "      \"blocks.7.mlp.fc1.bias\",\n",
      "      \"blocks.7.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2373046875\n",
      "  },\n",
      "  \"layer_8_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.7.attn.qkv.weight\",\n",
      "      \"blocks.7.attn.proj.weight\",\n",
      "      \"blocks.7.mlp.fc1.weight\",\n",
      "      \"blocks.7.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2373046875\n",
      "  },\n",
      "  \"layer_9_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.8.gamma_1\",\n",
      "      \"blocks.8.gamma_2\",\n",
      "      \"blocks.8.norm1.weight\",\n",
      "      \"blocks.8.norm1.bias\",\n",
      "      \"blocks.8.attn.q_bias\",\n",
      "      \"blocks.8.attn.v_bias\",\n",
      "      \"blocks.8.attn.relative_position_bias_table\",\n",
      "      \"blocks.8.attn.proj.bias\",\n",
      "      \"blocks.8.norm2.weight\",\n",
      "      \"blocks.8.norm2.bias\",\n",
      "      \"blocks.8.mlp.fc1.bias\",\n",
      "      \"blocks.8.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.31640625\n",
      "  },\n",
      "  \"layer_9_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.8.attn.qkv.weight\",\n",
      "      \"blocks.8.attn.proj.weight\",\n",
      "      \"blocks.8.mlp.fc1.weight\",\n",
      "      \"blocks.8.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.31640625\n",
      "  },\n",
      "  \"layer_10_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.9.gamma_1\",\n",
      "      \"blocks.9.gamma_2\",\n",
      "      \"blocks.9.norm1.weight\",\n",
      "      \"blocks.9.norm1.bias\",\n",
      "      \"blocks.9.attn.q_bias\",\n",
      "      \"blocks.9.attn.v_bias\",\n",
      "      \"blocks.9.attn.relative_position_bias_table\",\n",
      "      \"blocks.9.attn.proj.bias\",\n",
      "      \"blocks.9.norm2.weight\",\n",
      "      \"blocks.9.norm2.bias\",\n",
      "      \"blocks.9.mlp.fc1.bias\",\n",
      "      \"blocks.9.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.421875\n",
      "  },\n",
      "  \"layer_10_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.9.attn.qkv.weight\",\n",
      "      \"blocks.9.attn.proj.weight\",\n",
      "      \"blocks.9.mlp.fc1.weight\",\n",
      "      \"blocks.9.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.421875\n",
      "  },\n",
      "  \"layer_11_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.10.gamma_1\",\n",
      "      \"blocks.10.gamma_2\",\n",
      "      \"blocks.10.norm1.weight\",\n",
      "      \"blocks.10.norm1.bias\",\n",
      "      \"blocks.10.attn.q_bias\",\n",
      "      \"blocks.10.attn.v_bias\",\n",
      "      \"blocks.10.attn.relative_position_bias_table\",\n",
      "      \"blocks.10.attn.proj.bias\",\n",
      "      \"blocks.10.norm2.weight\",\n",
      "      \"blocks.10.norm2.bias\",\n",
      "      \"blocks.10.mlp.fc1.bias\",\n",
      "      \"blocks.10.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.5625\n",
      "  },\n",
      "  \"layer_11_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.10.attn.qkv.weight\",\n",
      "      \"blocks.10.attn.proj.weight\",\n",
      "      \"blocks.10.mlp.fc1.weight\",\n",
      "      \"blocks.10.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.5625\n",
      "  },\n",
      "  \"layer_12_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.11.gamma_1\",\n",
      "      \"blocks.11.gamma_2\",\n",
      "      \"blocks.11.norm1.weight\",\n",
      "      \"blocks.11.norm1.bias\",\n",
      "      \"blocks.11.attn.q_bias\",\n",
      "      \"blocks.11.attn.v_bias\",\n",
      "      \"blocks.11.attn.relative_position_bias_table\",\n",
      "      \"blocks.11.attn.proj.bias\",\n",
      "      \"blocks.11.norm2.weight\",\n",
      "      \"blocks.11.norm2.bias\",\n",
      "      \"blocks.11.mlp.fc1.bias\",\n",
      "      \"blocks.11.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.75\n",
      "  },\n",
      "  \"layer_12_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.11.attn.qkv.weight\",\n",
      "      \"blocks.11.attn.proj.weight\",\n",
      "      \"blocks.11.mlp.fc1.weight\",\n",
      "      \"blocks.11.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.75\n",
      "  },\n",
      "  \"layer_13_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"fc_norm.weight\",\n",
      "      \"fc_norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"layer_13_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use step level LR scheduler!\n",
      "Set warmup steps = 60\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = LabelSmoothingCrossEntropy()\n",
      "Auto resume checkpoint: \n",
      "Start training for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [0/7]  eta: 0:00:54  lr: 0.000000  min_lr: 0.000000  loss: 3.4996 (3.4996)  class_acc: 0.1875 (0.1875)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  time: 7.7264  data: 4.4407  max mem: 3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged stats: lr: 0.000017  min_lr: 0.000000  loss: 3.2738 (3.4032)  class_acc: 0.0938 (0.1250)  loss_scale: 32768.0000 (49152.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 26.2609 (inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [0/4]  eta: 0:00:14  loss: 3.7177 (3.7177)  acc1: 8.3333 (8.3333)  acc5: 56.2500 (56.2500)  time: 3.5353  data: 3.4671  max mem: 4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [3/4]  eta: 0:00:02  loss: 3.1346 (3.2899)  acc1: 8.3333 (16.1458)  acc5: 56.2500 (57.2917)  time: 2.1658  data: 2.0983  max mem: 4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Acc@1 16.146 Acc@5 57.292 loss 3.290\n",
      "Accuracy of the network on the 147 test images: 16.1%\n",
      "Max accuracy: 16.15%\n",
      "Training time 0:00:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:57, INFO Export to onnx...\n",
      "/opt/conda/lib/python3.8/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "17:41:00, INFO Model exported to: /tmp/tmpwov7qqu3onnx_tmp/model.onxx\n",
      "17:41:00, INFO Storing model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:00, INFO Removing cache...\n",
      "17:41:01, INFO Failed to remove cache...\n"
     ]
    }
   ],
   "source": [
    "fitted_classifier = classifier.fit(images_labels,\n",
    "                          base_model=\"dit-base-224-p16-500k-62d53a.pth\",\n",
    "                          validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7462e8f8-9b8c-4c9c-b4d0-da1e885852e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fitted_classifier.save(\"./fitted_model_best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
